{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 timestamp             user  \\\n",
      "0      2009-06-11 17:03:30  hatespeechradio   \n",
      "1      2009-06-11 17:13:11  champagnemanoir   \n",
      "2      2009-06-11 17:14:01     emperoranton   \n",
      "3      2009-06-11 17:15:20   seattlelawgirl   \n",
      "4      2009-06-11 17:23:56        fridayluv   \n",
      "...                    ...              ...   \n",
      "39935  2009-06-30 13:35:58      looney_mesh   \n",
      "39936  2009-06-30 13:37:13        kasyyoung   \n",
      "39937  2009-06-30 13:49:31   kimberanna_com   \n",
      "39938  2009-06-30 13:49:49   kimberanna_com   \n",
      "39939  2009-06-30 13:54:27    reneebarronmn   \n",
      "\n",
      "                                                 content  \n",
      "0      #followfriday (because I like to be a day earl...  \n",
      "1      RT @Ruth_Z don't tweet blindly... check out ho...  \n",
      "2      RT @Ohdoctah @micah @sarahrobinson Twitter Fol...  \n",
      "3      BTW, it's not #FollowFriday but @go2girlevents...  \n",
      "4      On Fridays don&#8217;t &#8216;pollute your str...  \n",
      "...                                                  ...  \n",
      "39935  Vote @Studmisile http://bit.ly/ufXtX and follo...  \n",
      "39936  RT @ReTweet_Central By @reebomber RT @Looney_M...  \n",
      "39937  RT @nicebio: #followfriday is a few days early...  \n",
      "39938  RT @LepowPhoto: #followfriday is a few days ea...  \n",
      "39939  RT @plumbusby @dpbkmb: #followfriday @makabra ...  \n",
      "\n",
      "[39940 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('twitter-small.tsv', sep='\\t', header=None,names=['timestamp', 'user', 'content'])\n",
    "df2 = pd.read_csv('twitter-larger.tsv', sep='\\t', header=None,names=['timestamp', 'user', 'content'])\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeList(df, G, name):\n",
    "    for index, row in df.iterrows():\n",
    "        user = row['user']\n",
    "        content = row['content']\n",
    "\n",
    "        words = content.split()\n",
    "        mentioned_users = [word[1:] for word in words if word.startswith('@')]\n",
    "        \n",
    "        for mentioned_user in mentioned_users:\n",
    "            if G.has_edge(user, mentioned_user):\n",
    "                #add weight when user has mentioned before\n",
    "                G[user][mentioned_user]['weight'] += 1\n",
    "            else:\n",
    "                #else, create edge\n",
    "                G.add_edge(user, mentioned_user, weight=1)\n",
    "\n",
    "    edge_list = nx.to_pandas_edgelist(G)\n",
    "    edge_list.to_csv(f'{name}.csv', index=False)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = nx.DiGraph()\n",
    "G2 = nx.DiGraph()\n",
    "\n",
    "G1 = makeList(df1, G1, 'small')\n",
    "G2 = makeList(df2, G2, 'larger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1 nodes: 102999\n",
      "G1 edges: 157025\n",
      "G2 nodes: 620352\n",
      "G2 edges: 1360894\n"
     ]
    }
   ],
   "source": [
    "def showNodesAndEdges(G, name):\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    num_edges = G.number_of_edges()\n",
    "    \n",
    "    print(f'{name} nodes:', num_nodes)\n",
    "    print(f'{name} edges:', num_edges)\n",
    "    \n",
    "showNodesAndEdges(G1, 'G1')\n",
    "showNodesAndEdges(G2, 'G2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1 strongly connected components: 101612\n",
      "G1 size of largest strongly connected component: 1110\n",
      "G1 weakly connected components: 4419\n",
      "G1 size of largest weakly connected component: 85860\n",
      "G2 strongly connected components: 598527\n",
      "G2 size of largest strongly connected component: 20068\n",
      "G2 weakly connected components: 17865\n",
      "G2 size of largest weakly connected component: 564050\n"
     ]
    }
   ],
   "source": [
    "def showWeakAndStrong(G, name):\n",
    "    strong_components = [len(c) for c in nx.strongly_connected_components(G)]\n",
    "    num_strong_components = len(strong_components)\n",
    "    largest_strong_component = max(strong_components) if strong_components else 0\n",
    "\n",
    "    weak_components = [len(c) for c in nx.weakly_connected_components(G)]\n",
    "    num_weak_components = len(weak_components)\n",
    "    largest_weak_component = max(weak_components) if weak_components else 0\n",
    "\n",
    "    print(f'{name} strongly connected components:', num_strong_components)\n",
    "    print(f'{name} size of largest strongly connected component:', largest_strong_component)\n",
    "    print(f'{name} weakly connected components:', num_weak_components)\n",
    "    print(f'{name} size of largest weakly connected component:', largest_weak_component)\n",
    "\n",
    "showWeakAndStrong(G1, 'G1')\n",
    "showWeakAndStrong(G2, 'G2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1 density: 1.4801543373296188e-05\n",
      "G2 density: 3.536296131767815e-06\n"
     ]
    }
   ],
   "source": [
    "def showDensity(G, name):\n",
    "    density = nx.density(G)\n",
    "    print(f'{name} density:', density)\n",
    "\n",
    "showDensity(G1, 'G1')\n",
    "showDensity(G2, 'G2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1 average clustering coefficient: 0.019285324303747912\n",
      "G2 average clustering coefficient: 0.030628227982516916\n"
     ]
    }
   ],
   "source": [
    "#average clustering coefficient\n",
    "def showACC(G, name):\n",
    "    ACC = nx.average_clustering(G)\n",
    "    print(f'{name} average clustering coefficient:', ACC)\n",
    "\n",
    "showACC(G1, 'G1')\n",
    "showACC(G2, 'G2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'total_distance' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     average_distance \u001b[38;5;241m=\u001b[39m total_distance \u001b[38;5;241m/\u001b[39m num_pairs \u001b[38;5;28;01mif\u001b[39;00m num_pairs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m average distance:\u001b[39m\u001b[38;5;124m'\u001b[39m, average_distance)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mshowAverageDistance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mG1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m showAverageDistance(G2, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[1;32mIn[24], line 12\u001b[0m, in \u001b[0;36mshowAverageDistance\u001b[1;34m(G, name, sample_size)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     distance \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mshortest_path_length(giant_component, source\u001b[38;5;241m=\u001b[39msampled_nodes[i], target\u001b[38;5;241m=\u001b[39msampled_nodes[j])\n\u001b[1;32m---> 12\u001b[0m     total_distance \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m distance\n\u001b[0;32m     13\u001b[0m     num_pairs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mNetworkXNoPath:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'total_distance' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def showAverageDistance(G, name, sample_size=100):\n",
    "    G_undirected = G.to_undirected()\n",
    "    largest_component = max(nx.connected_components(G_undirected), key=len)\n",
    "    giant_component = G_undirected.subgraph(largest_component)\n",
    "    nodes = list(giant_component.nodes)\n",
    "    sampled_nodes = random.sample(nodes, min(sample_size, len(nodes)))\n",
    "    \n",
    "    total_distance = 0\n",
    "    num_pairs = 0\n",
    "\n",
    "    for i in range(len(sampled_nodes)):\n",
    "        for j in range(i + 1, len(sampled_nodes)):\n",
    "            try:\n",
    "                distance = nx.shortest_path_length(giant_component, source=sampled_nodes[i], target=sampled_nodes[j])\n",
    "                total_distance += distance\n",
    "                num_pairs += 1\n",
    "            except nx.NetworkXNoPath:\n",
    "                continue  \n",
    "\n",
    "    average_distance = total_distance / num_pairs if num_pairs > 0 else float('inf')\n",
    "    print(f'{name} average distance:', average_distance)\n",
    "\n",
    "showAverageDistance(G1, 'G1', 100)\n",
    "showAverageDistance(G2, 'G2', 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
